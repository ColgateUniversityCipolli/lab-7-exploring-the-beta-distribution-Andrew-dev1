\documentclass{article}
\usepackage{amsmath} %This allows me to use the align functionality.
                     %If you find yourself trying to replicate
                     %something you found online, ensure you're
                     %loading the necessary packages!
\usepackage{amsfonts}%Math font
\usepackage{graphicx}%For including graphics
\usepackage{hyperref}%For Hyperlinks
\usepackage[shortlabels]{enumitem}% For enumerated lists with labels specified
                                  % We had to run tlmgr_install("enumitem") in R
\hypersetup{colorlinks = true,citecolor=black} %set citations to have black (not green) color
\usepackage{natbib}        %For the bibliography
\setlength{\bibsep}{0pt plus 0.3ex}
\bibliographystyle{apalike}%For the bibliography
\usepackage[margin=0.50in]{geometry}
\usepackage{float}
\usepackage{multicol}

%fix for figures
\usepackage{caption}
\newenvironment{Figure}
  {\par\medskip\noindent\minipage{\linewidth}}
  {\endminipage\par\medskip}
\begin{document}

\vspace{-1in}
\title{Lab 8 -- MATH 240 -- Computational Statistics}

\author{
  Andrew Li \\
  Colgate University  \\
  Mathematics Department  \\
  {\tt ali@colgate.edu}
}

\date{}

\maketitle

\begin{multicols}{2}
\begin{abstract}
In this lab, we explored the beta distribution has been explored thoroughly by working with its various properties, probability distributions, and parameters. By changing the parameters, we can evaluate the effects on its statistical values such as mean, variance, skewness, and excess kurtosis. To analyze real world data on global deaths from the World Bank, we made 2 point estimators (Method of Moments and Maximum Likelihood Estimations), which both work well but the \emph{MLE} works slightly better. 

\end{abstract}

\noindent \textbf{Keywords:} point estimations; parameters; probability distributions; 

\section{Introduction}
The beta distribution is a continuous distribution that can be used to model the variability of a random variable $X$ that ranges from $0$ to $1$. It is useful for modeling proportions, probabilities, or rates as its statistical characteristics are versatile enough to assume many different shapes based on its input parameters (Given that $\alpha >$ 0, $\beta >$ 0). 

By exploring its properties, the effects of various inputs can be seen to answer our questions about what the beta distribution is, what it can be used for, what are some of its properties, and what useful inferences can be drawn from simulation and real data analysis. 

The \texttt{R} packages that were used are tidyverse\citep{tidyverse} for data cleaning and plotting, patchwork\citep{patchwork} for combining graphs, e1071\citep{e1071} for calculating properties, xtable\citep{xtable} for table creation, nleqslv\citep{nleqslv} for point estimation calculations, and cumstats\citep{cumstats} for measuring cumulative statistics. 

%\begin{Figure}
%\includegraphics{screenshot}
%\end{Figure}

\section{Density Functions and Parameters}
The beta distribution has a probability density function defined as: 
\[
f(x; \alpha, \beta) = \frac{\Gamma(\alpha + \beta)}{\Gamma\alpha\Gamma\beta} \, x^{\alpha - 1} (1 - x)^{\beta - 1}I(x \in [0,1])
\] 

Knowing that $x$ stays within 0 to 1, we looked at the different cases of \(Beta(\alpha, \beta)\) where \(Beta(2, 5), Beta(5,5), Beta(5, 2), \text{and }Beta(0.5, 0.5)\) and explored their properties. 
<<echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, size='scriptsize'>>=
library(tidyverse)
library(e1071)
library(patchwork)
library(xtable)

## create a function to calculate the mean, variance, skewness, and excess kurtosis
calculate <- function(alpha, beta){
  beta.mean <- alpha/ (alpha +beta)
  beta.variance <- (alpha*beta)/ ((alpha +beta)^2 *(alpha+beta+1))
  beta.skewness <- (2*(beta-alpha)* (alpha+beta+1)^(1/2)) /
    ((alpha+beta+2)*(alpha*beta)^(1/2))
  beta.kurtosis <-6*((alpha -beta)^2 *(alpha+beta+1) - ((alpha*beta)*(alpha+beta+2)))/ 
    ((alpha*beta)*(alpha+beta+2)*(alpha+beta+3))
  
  dat.comparison <- tibble() %>%
    summarize(variable = sprintf("Beta(%g,%g)", alpha,beta),
              mean = beta.mean,
              variance = beta.variance,
              skewness = beta.skewness,
              excess.kurtosis = beta.kurtosis
    )  
  return(dat.comparison)
}

betas <- tibble(alpha = c(2,5,5,0.5), beta = c(5,5,2,0.5))
value.dat <- betas %>%
  pmap_dfr(~calculate(..1, ..2))

@
The beta distributions for each plot is graphed together in Figure \ref{plot1}.

\section{Properties}
We calculated the population moments using numerical integration shown in Table \ref{table1}.

Since the distribution's shape is affected by its parameters, the population characteristics are also controlled by them. To prove that its possible to approximate what the population distribution might be, we can connect our numerical summaries and graphs to the actual distribution by generating random data and comparing the calculated results against those from the known distribution, shown in Figure \ref{plot2}. The properties of mean, variance, skewness, and excess kurtosis are then compared against those from the population characteristics in Table \ref{table1}.

Then we explored how the law of large numbers is proven to be true as the increasing sample size decreases the variability in the different properties of the data across different samples. This is shown in Figure \ref{plot3} and remains true when we ran random samples and the graphical representations of the properties end up converging towards the population values as sample size increased. 



\begin{table}[H]
\centering
\begin{tabular}{rlrrrr}
  \hline
 & variable & mean & variance & skewness & kurtosis \\ 
  \hline
1 & Beta(0.5,0.5) & 0.50 & 0.12 & 0.00 & -1.50 \\ 
  2 & Beta(2,5) & 0.29 & 0.03 & 0.60 & -0.12 \\ 
  3 & Beta(5,2) & 0.71 & 0.03 & -0.60 & -0.12 \\ 
  4 & Beta(5,5) & 0.50 & 0.02 & 0.00 & -0.46 \\ 
  5 & Sample Beta(0.5,0.5) & 0.52 & 0.12 & -0.11 & 1.55 \\ 
  6 & Sample Beta(2,5) & 0.29 & 0.03 & 0.57 & 2.78 \\ 
  7 & Sample Beta(5,2) & 0.71 & 0.03 & -0.74 & 3.22 \\ 
  8 & Sample Beta(5,5) & 0.50 & 0.02 & 0.06 & 2.54 \\ 
   \hline
\end{tabular} \caption{population moments } \label{table1}
\end{table}

\section{Estimators}
We created a Method of Moments (MOM) point estimator and Maximum Likelihood Estimator (MLE) to calculate the two unknown parameters of $\alpha$ and $\beta$. To use the MOM, we had to find the first two moments of the beta distribution . The first moment is calculated as $\frac{\alpha}{\alpha + \beta}$ while the second is denoted by $\frac {\alpha * (\alpha +1)}{(\alpha + \beta + 1) * (\alpha +\beta)}$. Normally, you can create a symbol of equations and, through substitution, find out what each moment would be using only the sample value for the MOM, and the MLE would have required taking the likelihood of every x and then optimizing the values to find the maximum. We reduced the computations required with \texttt{R}. 



<<eval = F, echo=F, warning=F, message=F, size= 'scriptsize' >>=
MOM.beta <- function(data, par){
  alpha <- par[1]
  beta <- par[2]
  EX1 <- alpha/ (alpha +beta)
  EX2 <- (alpha * (alpha +1))/((alpha + beta + 1) * (alpha +beta))
  m1 <- mean(data)
  m2 <- mean(data^2)
  
  return( c(EX1 - m1, EX2 - m2) )
}

MLE.beta <- function(data, par, neg = F){
  alpha <- par[1]
  beta <- par[2]
  ll <- sum(log(dbeta(x = data, shape1 = alpha, shape2 = beta)))
  
  return(ifelse(neg, -ll, ll))
}
@


\section{Example}
After running a thousand samples of size 266 with $\alpha$ = 8, $\beta$ = 950 to model the world death data, we were able to compare the accuracy (bias) and variability (precision) of the two point estimators. Looking at the Figure \ref{plot4}, it can be seen that the MLE has less variability because its values doesn't spread as much and has a taller peak. This is further verified when looking at the numerical values in table \ref{table2}, so the MLE is the better point estimator.

<<echo=FALSE, eval=T, message=FALSE, warning=FALSE, size='scriptsize'>>=
library(nleqslv)
MOM.beta <- function(data, par){
  alpha <- par[1]
  beta <- par[2]
  EX1 <- alpha/ (alpha +beta)
  EX2 <- (alpha * (alpha +1))/((alpha + beta + 1) * (alpha +beta))
  m1 <- mean(data)
  m2 <- mean(data^2)
  
  return( c(EX1 - m1, EX2 - m2) )
}

MLE.beta <- function(data, par, neg = F){
  alpha <- par[1]
  beta <- par[2]
  ll <- sum(log(dbeta(x = data, shape1 = alpha, shape2 = beta)))
  
  return(ifelse(neg, -ll, ll))
}

alpha = 8
beta = 950
result <- tibble()
for(i in 1:1000){
  set.seed(7272+i)
  beta.sample <- rbeta(n = 266,      # sample size
                       shape1 = alpha,   # alpha parameter
                       shape2 = beta) # beta parameter

  moms.internal <- nleqslv(x = c(1,1),
                           fn = MOM.beta,
                           data= beta.sample)
  mles.internal <- optim(par = c(1,1),
                         fn = MLE.beta,
                         data= beta.sample,
                         neg=T)
  result <- bind_rows(result, tibble(moms.alpha = moms.internal$x[1],
                                     moms.beta = moms.internal$x[2],
                                     mles.alpha = mles.internal$par[1],
                                     mles.beta = mles.internal$par[2]))
}


values = function(theta.hats, theta){
  (bias <- mean(theta.hats) - theta)
  (precision <- 1/var(theta.hats))
  (mse <- var(theta.hats) + bias^2)
  return(tibble(bias, precision, mse))
}

a.moms <- values(result$moms.alpha, alpha)
b.moms <- values(result$moms.beta, beta)
a.mles <- values(result$mles.alpha, alpha)
b.mles <- values(result$mles.beta, beta)

accuracy <- tibble()|> 
  bind_rows(a.moms, b.moms, a.mles, b.mles) |> 
  mutate(names = c("moms alpha", "moms beta", "mles alpha", "mles beta"),
        actual = c(alpha, beta, alpha, beta),
        estimated = c(mean(result$moms.alpha), mean(result$moms.beta), 
                      mean(result$mles.alpha), mean(result$mles.beta))
         )
table2 <- xtable(accuracy,
                 caption = "Table to compare estimator values",
                 label = "table2")

@
<<echo=FALSE, eval=TRUE, results="asis">>=
print(table2,
      table.placement = "H", 
      include.rownames = FALSE, 
      size = "small", 
      caption.placement = "bottom")
@

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Bibliography
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{2em}


\begin{tiny}
\bibliography{bib}
\end{tiny}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Appendix
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Appendix}

<<plot1, echo=FALSE, eval=F, message=FALSE, warning=FALSE, size='scriptsize'>>=
# generate a grid of points and calculate beta values for different alphas and betas
sequence <- seq(0, 1.0, length.out=500)
figure1.data <- tibble(x = sequence)|>   
  mutate(beta.2.5 = dbeta(x, 2, 5),
         beta.5.5 = dbeta(x, 5, 5),
         beta.5.2 = dbeta(x, 5, 2),
         beta.half = dbeta(x, 0.5, 0.5)
         )

# plot beta distributions
(beta.distributions <- ggplot(data= figure1.data)+                     # specify data
  geom_line(aes(x=x, y=beta.2.5, color="Beta(2,5)")) +                
  geom_line(aes(x=x, y=beta.5.5, color="Beta(5,5)")) + 
  geom_line(aes(x=x, y=beta.5.2, color="Beta(5,2)")) + 
  geom_line(aes(x=x, y=beta.half, color="Beta(0.5,0.5)")) + 
  geom_hline(yintercept=0)+                                            # plot x axis
  theme_bw()+                                                          # change theme
  xlab("x")+                                                           # label x axis
  ylab("Density")+                                                     # label y axis
  scale_color_manual("", values = c("black", "lightblue", "purple",
                                    "orange"))+                 # change colors
  theme(legend.position = "bottom"))
@
\begin{figure}[H]
\begin{center}
<<echo=FALSE, warning=FALSE, message=FALSE, fig.dim=c(5,3.5)>>=
<<plot1>>
@
\caption{Distributions of different beta plots}
\label{plot1} 
\end{center}
\end{figure}

<<plot2, echo=FALSE, eval=F, message=FALSE, warning=FALSE, size='scriptsize'>>=
set.seed(7272)

sample.size <- 500
beta.sample1 <- rbeta(n = sample.size,  # sample size
                     shape1 = 2,   # alpha parameter
                     shape2 = 5)    # beta parameter

sample.df1 <- as.data.frame(beta.sample1)
betaplot1 <- ggplot(sample.df1, aes(x= beta.sample1))+
  xlab("Beta(2,5)")+
  geom_histogram(aes(y = after_stat(density)),
                 breaks = seq(from = 0, to = 1, by = 0.075))


beta.sample2 <- rbeta(n = sample.size,  # sample size
                      shape1 = 5,   # alpha parameter
                      shape2 = 5)    # beta parameter
sample.df2 <- as.data.frame(beta.sample2)
betaplot2 <- ggplot(sample.df2, aes(x= beta.sample2))+
  xlab("Beta(5,5)")+
  geom_histogram(aes(y = after_stat(density)),
                 breaks = seq(from = 0, to = 1, by = 0.075))


beta.sample3 <- rbeta(n = sample.size,  # sample size
                      shape1 = 5,   # alpha parameter
                      shape2 = 2)    # beta parameter
sample.df3 <- as.data.frame(beta.sample3)
betaplot3 <- ggplot(sample.df3, aes(x= beta.sample3))+
  xlab("Beta(5,2)")+
  geom_histogram(aes(y = after_stat(density)),
                 breaks = seq(from = 0, to = 1, by = 0.075))

beta.sample4 <- rbeta(n = sample.size,  # sample size
                      shape1 = 0.5,   # alpha parameter
                      shape2 = 0.5)    # beta parameter
sample.df4 <- as.data.frame(beta.sample4)
betaplot4 <- ggplot(sample.df4, aes(x= beta.sample4))+
  xlab("Beta(0.5,0.5)")+
  geom_histogram(aes(y = after_stat(density)),
                 breaks = seq(from = 0, to = 1, by = 0.1))

# create a comparative table to work with
calculate2 <- function(beta.sample, num1, num2){
  tibs <- tibble()|>
    summarize(variable = sprintf("Sample Beta(%g,%g)", num1, num2),
            mean = mean(beta.sample),
            variance = var(beta.sample),
            skewness = skewness(beta.sample),
            excess.kurtosis = kurtosis(beta.sample))
  return(tibs)
}
samples <- list(
  list(beta.sample1, 2, 5),
  list(beta.sample2, 5, 5),
  list(beta.sample3, 5, 2),
  list(beta.sample4, 0.5, 0.5))

sample.values.dat <- map_dfr(samples, ~ calculate2(.x[[1]], .x[[2]], .x[[3]]))
comparison <- merge(value.dat, sample.values.dat, all.y = T, all.x = T)

(betaplot1 + betaplot2)/(betaplot3 + betaplot4)
@
\begin{figure}[H]
\begin{center}
<<echo=FALSE, warning=FALSE, message=FALSE, fig.dim=c(5,3.5)>>=
<<plot2>>
@
\caption{Histograms of densities of beta samples}
\label{plot2} 
\end{center}
\end{figure}


<<plot3, echo=FALSE, eval=F, message=FALSE, warning=FALSE, size='scriptsize'>>=
library(cumstats)

# generate a grid of points and calculate culmmulative data
dat.beta.2.5 <- tibble(x = beta.sample1)|>   
  mutate(beta.pdf = dbeta(x, shape1 = 2, shape2 = 5),
         cummulative.mean = cummean(x),
         cummulative.variance = cumvar(x),
         cummulative.skewness = cumskew(x),
         cummulative.kurtosis = cumkurt(x)
         )

mean.plot <- ggplot()+
  geom_line(data = dat.beta.2.5, aes(x = 1:500, y = cummulative.mean))+
  geom_hline(yintercept = comparison$mean[2])+
  theme_bw()+                                                          # change theme
  xlab("x")+                                                           # label x axis
  ylab("Cumulative means")

variance.plot <- ggplot()+
  geom_line(data = dat.beta.2.5, aes(x = 1:500, y = cummulative.variance))+
  geom_hline(yintercept = comparison$variance[2])+
  theme_bw()+                                                          # change theme
  xlab("x")+                                                           # label x axis
  ylab("variances")

skewness.plot <- ggplot()+
  geom_line(data = dat.beta.2.5, aes(x = 1:500, y = cummulative.skewness))+
  geom_hline(yintercept = comparison$skewness[2])+
  theme_bw()+                                                          # change theme
  xlab("x")+                                                           # label x axis
  ylab("Skewnesses")

kurtosis.plot <- ggplot()+
  geom_line(data = dat.beta.2.5, aes(x = 1:500, y = cummulative.kurtosis))+
  geom_hline(yintercept = comparison$excess.kurtosis[2])+
  theme_bw()+                                                          # change theme
  xlab("x")+                                                           # label x axis
  ylab("Kurts")
 
for(i in 2:50){
  set.seed(7272 + i)
  beta.sample <- rbeta(n = sample.size,  # sample size
                        shape1 = 2,   # alpha parameter
                        shape2 = 5)
  loops.data <- tibble(x = beta.sample)|>   # generate a grid of points
    mutate(beta.pdf = dbeta(x, shape1 = 2, shape2 = 5),
           cummulative.mean = cummean(x),
           cummulative.variance = cumvar(x),
           cummulative.skewness = cumskew(x),
           cummulative.kurtosis = cumkurt(x)
    )  
  mean.plot <- mean.plot +
    geom_line(data = loops.data, aes(x = 1:500, y = cummulative.mean), color= i)
  variance.plot <- variance.plot +
    geom_line(data = loops.data, aes(x = 1:500, y = cummulative.variance), color= i)
  skewness.plot <- skewness.plot +
    geom_line(data = loops.data, aes(x = 1:500, y = cummulative.skewness), color= i)
  kurtosis.plot <- kurtosis.plot +
    geom_line(data = loops.data, aes(x = 1:500, y = cummulative.kurtosis), color= i)
}

(mean.plot + variance.plot) / (skewness.plot + kurtosis.plot)
@
\begin{figure}[H]
\begin{center}
<<echo=FALSE, warning=FALSE, message=FALSE, fig.dim=c(5,3.5)>>=
<<plot3>>
@
\caption{Graphical comparison of random samples to population data}
\label{plot3} 
\end{center}
\end{figure}

<<plot4, echo=FALSE, eval=F, message=FALSE, warning=FALSE, size='scriptsize'>>=
plot.moms.alpha = ggplot(data = result, aes(x = moms.alpha)) + 
  geom_density(fill = "#FD8A8A")+ 
  theme_bw() +
  geom_hline(yintercept=0)+
  xlab("alpha values from moms")+
  ggtitle("Estimated density for moms")

plot.moms.beta = ggplot(data = result, aes(x = moms.beta)) + 
  geom_density(fill = "#A8D1D1")+ 
  theme_bw() +
  geom_hline(yintercept=0)+
  xlab("beta values from moms")+
  ggtitle("Estimated density for moms")

plot.mles.alpha = ggplot(data = result, aes(x = mles.alpha)) + 
  geom_density(fill = "#d5d1e9")+ 
  theme_bw() +
  geom_hline(yintercept=0)+
  xlab("alpha values from mles")+
  ggtitle("Estimated density for mles")

plot.mles.beta = ggplot(data = result, aes(x = mles.beta)) + 
  geom_density(fill = "#f5cf9f")+ 
  theme_bw() +
  geom_hline(yintercept=0)+
  xlab("beta values from mles")+
  ggtitle("Estimated density for mles")

(plot.moms.alpha + plot.moms.beta) / (plot.mles.alpha + plot.mles.beta)
@
\begin{figure}[H]
\begin{center}
<<echo=FALSE, warning=FALSE, message=FALSE, fig.dim=c(5,3.5)>>=
<<plot4>>
@
\caption{Densities of alpha and beta values from point estimators}
\label{plot4} 
\end{center}
\end{figure}


\end{multicols}
\end{document}